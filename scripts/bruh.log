| distributed init (rank 0): env://, gpu 0
Namespace(att_root='/home/data/att_maps', auto_resume=True, batch_size=128, clip_grad=None, color_jitter=0.0, data_path='/home/data/train', device='cuda', dist_backend='nccl', dist_on_itp=False, dist_url='env://', distributed=True, drop_path=0.0, epochs=1600, gpu=0, imagenet_default_mean_and_std=True, input_size=224, local_rank=0, log_dir=None, lr=0.00015, mask_ratio=0.75, min_lr=1e-05, model='pretrain_mae_base_patch16_224', momentum=0.9, normlize_target=True, num_workers=10, opt='adamw', opt_betas=[0.9, 0.95], opt_eps=1e-08, output_dir='/home/code/saliency_mae/outputs/pretrain_mae_base_patch16_224_salient_mask', pin_mem=True, rank=0, resume='', save_ckpt_freq=20, seed=0, start_epoch=0, train_interpolation='bicubic', warmup_epochs=40, warmup_lr=1e-06, warmup_steps=-1, weight_decay=0.05, weight_decay_end=None, world_size=1)
Creating model: pretrain_mae_base_patch16_224
CKPT loaded <All keys matched successfully>
Patch size = (16, 16)
Data Aug = (DataAugmentationForBEiT,
  transform = Compose(
    RandomResizedCrop(size=(224, 224), scale=(0.08, 1.0), ratio=(0.75, 1.3333), interpolation=bilinear)
    ToTensor()
    Normalize(mean=tensor([0.4850, 0.4560, 0.4060]), std=tensor([0.2290, 0.2240, 0.2250]))
),
)
Traceback (most recent call last):
  File "/home/code/saliency_mae/MAE-pytorch/run_mae_pretrainingv2.py", line 282, in <module>
    main(opts)
  File "/home/code/saliency_mae/MAE-pytorch/run_mae_pretrainingv2.py", line 174, in main
    dataset_train = build_pretraining_dataset(args)
  File "/home/code/saliency_mae/MAE-pytorch/datasets.py", line 75, in build_pretraining_dataset
    return ImageFolderWithAttMap(args, args.data_path, transform=transform)
  File "/home/code/saliency_mae/MAE-pytorch/datasets.py", line 56, in __init__
    super().__init__(*args, **kwargs)
  File "/home/code/saliency_mae/MAE-pytorch/dataset_folder.py", line 244, in __init__
    is_valid_file=is_valid_file)
  File "/home/code/saliency_mae/MAE-pytorch/dataset_folder.py", line 122, in __init__
    raise RuntimeError(msg)
RuntimeError: Found 0 files in subfolders of: /home/data/train
Supported extensions are: .jpg,.jpeg,.png,.ppm,.bmp,.pgm,.tif,.tiff,.webp
/opt/conda/lib/python3.7/site-packages/torch/distributed/launch.py:186: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use_env is set by default in torchrun.
If your script expects `--local_rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  FutureWarning,
ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 0 (pid: 32710) of binary: /opt/conda/bin/python
Traceback (most recent call last):
  File "/opt/conda/lib/python3.7/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/opt/conda/lib/python3.7/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/opt/conda/lib/python3.7/site-packages/torch/distributed/launch.py", line 193, in <module>
    main()
  File "/opt/conda/lib/python3.7/site-packages/torch/distributed/launch.py", line 189, in main
    launch(args)
  File "/opt/conda/lib/python3.7/site-packages/torch/distributed/launch.py", line 174, in launch
    run(args)
  File "/opt/conda/lib/python3.7/site-packages/torch/distributed/run.py", line 755, in run
    )(*cmd_args)
  File "/opt/conda/lib/python3.7/site-packages/torch/distributed/launcher/api.py", line 131, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/opt/conda/lib/python3.7/site-packages/torch/distributed/launcher/api.py", line 247, in launch_agent
    failures=result.failures,
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
/home/code/saliency_mae/MAE-pytorch/run_mae_pretrainingv2.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2022-12-08_05:02:44
  host      : deeplearning-finalproj-vm.c.titanium-scope-363920.internal
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 32710)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
